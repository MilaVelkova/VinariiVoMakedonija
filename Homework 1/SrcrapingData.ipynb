{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##<font color=\"lightgreen\">Scraping the winetourism website</font>##"
      ],
      "metadata": {
        "id": "LGWMc8gIRXF2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "TUNbw680g1FZ"
      },
      "outputs": [],
      "source": [
        "#Import libraries that we will need\n",
        "import requests\n",
        "from bs4 import BeautifulSoup as bs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seting the url of the first page that we are going to scrape\n",
        "#In a sense that we can get more other data, we only change the website and the selectors that we work with, all other functionalities are the same.\n",
        "url=\"https://www.winetourism.com/wineries-in-north-macedonia/\"\n",
        "#Getting the response from the web site\n",
        "response = requests.get(url)\n",
        "#Checking if the websie allows us to scrape it by seeing the response. It is 200 so we are good to go\n",
        "response.status_code\n",
        "#Beautifying the html so we can easily select the needed elements with Beautiful Soup\n",
        "raw_html = response.text\n",
        "beautified_html = bs(raw_html, 'html.parser')\n",
        "wine_card = beautified_html.select(\".blog-item\")\n",
        "#Extracting the data using css selectors with Beautiful Soup\n",
        "wine_card\n",
        "winary_card = beautified_html.select(\".blog-item .image-wrapper img\")\n",
        "winary_names = [item['alt'] for item in winary_card]\n",
        "\n",
        "root_url = \"https://www.winetourism.com/\"\n",
        "\n",
        "winary_images_links = [str(root_url[:-1]) + \"\" + str(item['src']) for item in winary_card]\n",
        "winary_names\n",
        "\n",
        "winary_description = beautified_html.select(\".blog-item .blog-content .blog-excerpt\")\n",
        "winary_description = [item.text.replace(\"\\n\", \"\") for item in winary_description]\n",
        "#Exctracted info: Winary names, Winary Description, Winary images links\n",
        "#Other data in the csv file is Coordinates and rating which is manually written for this particular dataset"
      ],
      "metadata": {
        "id": "4ILwv-plhKTK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining Data Frame so we can easily display and viasulize the data in table\n",
        "import pandas as pd\n",
        "item_dict = dict()\n",
        "\n",
        "item_dict[\"Winary Name\"] = winary_names\n",
        "item_dict[\"Winary Description\"] = winary_description\n",
        "item_dict[\"Winary Image Link\"] = winary_images_links\n",
        "\n",
        "df = pd.DataFrame(item_dict)"
      ],
      "metadata": {
        "id": "-hmQmSg0jWao"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replacing_empty_strings_with_nulls(data):\n",
        "  import numpy as np\n",
        "  data.replace(\" \", np.nan, inplace=True)\n",
        "  return data"
      ],
      "metadata": {
        "id": "XQj8XFP76ATU"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropping_duplicates_by_name(data):\n",
        "  data.drop_duplicates(subset=['Winary Name'], inplace=True)\n",
        "  return data"
      ],
      "metadata": {
        "id": "C5aSExOl6Ngu"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###<font color=\"lightgreen\">Scraping images for displaying</font>###"
      ],
      "metadata": {
        "id": "nBLOL4SbMLQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scraping_images():\n",
        "  import requests\n",
        "  from bs4 import BeautifulSoup as bs\n",
        "\n",
        "  images_url = \"https://unsplash.com/s/photos/wineries\"\n",
        "\n",
        "  response = requests.get(images_url)\n",
        "  response.status_code\n",
        "\n",
        "  raw_html = response.text\n",
        "  beautified_html = bs(raw_html, 'html.parser')\n",
        "\n",
        "  images = beautified_html.select(\"img\")\n",
        "  images = [item['src'] for item in images]\n",
        "  images = [images[i] for i in range(len(images)) if i%2 == 0]\n",
        "  return images"
      ],
      "metadata": {
        "id": "0lVDhOxPNLgj"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pipe Class##"
      ],
      "metadata": {
        "id": "iTBpeIZV-Tes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipe class\n",
        "\n",
        "class Pipe:\n",
        "  def __init__(self):\n",
        "      self.filters = list()\n",
        "\n",
        "  def add(self, filter):\n",
        "      self.filters.append(filter)\n",
        "\n",
        "  def execute(self, message):\n",
        "      print(\"Executing pipeline...\")\n",
        "      for message_filter in self.filters:\n",
        "          print('Filtering with',message_filter)\n",
        "          message=message_filter(message)\n",
        "      print(\"Done.\")\n",
        "      return message"
      ],
      "metadata": {
        "id": "aYjJw8JC128U"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pipe Execution##"
      ],
      "metadata": {
        "id": "xwlzVEJ5-VMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipe()\n",
        "pipe.add(replacing_empty_strings_with_nulls)\n",
        "pipe.add(dropping_duplicates_by_name)\n",
        "final_dataset = pipe.execute(df)\n",
        "final_dataset.to_excel(\"filtered.xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tsQtjJT16cJ",
        "outputId": "594b4d29-6d28-4d41-cd8b-7f91201eaa1a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing pipeline...\n",
            "Filtering with <function replacing_empty_strings_with_nulls at 0x79bdac4c8ca0>\n",
            "Filtering with <function dropping_duplicates_by_name at 0x79bda9fcbbe0>\n",
            "Done.\n"
          ]
        }
      ]
    }
  ]
}